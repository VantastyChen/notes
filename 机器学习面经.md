## 一 逻辑回归&交叉熵（重点）
LR真的是经久不衰啊，其实能问的地方好多好多，关于sigmoid函数其实可以从指数函数族的角度推导推导，然后就是交叉熵啦，最基本的就是从极大似然角度推导交叉熵。LR的基础推导看[这里](https://zhuanlan.zhihu.com/p/34325602) 。

####  1.1、简单介绍LR：

从指数函数族的角度和线性回归两个方面回答的：指数函数族方面就是先验的认为二分类问题服从伯努利分布，然后可以推出sigmoid函数(详见吴恩达cs229课件)；线性回归方面就是我们希望做分类的时候会给出一个阈值，超过就是1低于就是0，那就是个分段函数了，比较难以求解和优化，所以选了一个sigmoid函数作为二分类的近似。注意，这里用的是“可能性”，而非数学上的“概率”，logisitc回归的结果并非数学定义中的概率值，不可以直接当做概率值来用。该结果往往用于和其他特征值加权求和，而非直接相乘。

逻辑回归假设数据服从伯努利分布,通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的

 这里面其实包含了5个点 1：逻辑回归的假设，2：逻辑回归的损失函数，3：逻辑回归的求解方法，4：逻辑回归的目的，5:逻辑回归如何分类。这些问题是考核你对逻辑回归的基本了解。

#### 1.2、逻辑回归的基本假设

任何的模型都是有自己的假设，在这个假设下模型才是适用的。逻辑回归的第一个基本假设是假设数据服从伯努利分布。伯努利分布有一个简单的例子是抛硬币，抛中为正面的概率是p,抛中为负面的概率是1−p.在逻辑回归这个模型里面是假设 hθ(x) 为样本为正的概率，1−hθ(x)为样本为负的概率。那么整个模型可以描述为



$$
h_\theta\left(x;\theta \right )=p
$$


逻辑回归的第二个假设是假设样本为正的概率是 



$$
p=\frac{1}{1+e^{-\theta^{T} x}}
$$



所以逻辑回归的最终形式 
$$
h_\theta\left(x;\theta \right )=\frac{1}{1+e^{-\theta^{T} x}}
$$
#### 1.3、逻辑回归的损失函数


逻辑回归的损失函数是它的极大似然函数
$$
L_\theta\left(x\right )= \prod _{i=1}^{m}h_\theta(x^{i};\theta )^{y{i}}*(1-h_\theta(x^{i};\theta))^{1-y^{i}}
$$

#### 1.4、逻辑回归的求解方法

 - 由于该极大似然函数无法直接求解，我们一般通过对该函数进行梯度下降来不断逼急最优解。在这个地方其实会有个加分的项，考察你对其他优化方法的了解。因为就梯度下降本身来看的话就有随机梯度下降，批梯度下降，small batch 梯度下降三种方式，面试官可能会问这三种方式的优劣以及如何选择最合适的梯度下降方式。
     - 简单来说 批梯度下降会获得全局最优解，缺点是在更新每个参数的时候需要遍历所有的数据，计算量会很大，并且会有很多的冗余计算，导致的结果是当数据量大的时候，每个参数的更新都会很慢。
     - 随机梯度下降是以高方差频繁更新，优点是使得sgd会跳到新的和潜在更好的局部最优解，缺点是使得收敛到局部最优解的过程更加的复杂。
小批量梯度下降结合了sgd和batch gd的优点，每次更新的时候使用n个样本。减少了参数更新的次数，可以达到更加稳定收敛结果，一般在深度学习当中我们采用这种方法。
 - 其实这里还有一个隐藏的更加深的加分项，看你了不了解诸如Adam，动量法等优化方法。因为上述方法其实还有两个致命的问题。
    - 第一个是如何对模型选择合适的学习率。自始至终保持同样的学习率其实不太合适。因为一开始参数刚刚开始学习的时候，此时的参数和最优解隔的比较远，需要保持一个较大的学习率尽快逼近最优解。但是学习到后面的时候，参数和最优解已经隔的比较近了，你还保持最初的学习率，容易越过最优点，在最优点附近来回振荡，通俗一点说，就很容易学过头了，跑偏了。
    - 第二个是如何对参数选择合适的学习率。在实践中，对每个参数都保持的同样的学习率也是很不合理的。有些参数更新频繁，那么学习率可以适当小一点。有些参数更新缓慢，那么学习率就应该大一点。

#### 1.5、逻辑回归的目的
该函数的目的便是将数据二分类，提高准确率。

#### 1.6、逻辑回归如何分类?多分类？
- 分类 逻辑回归作为一个回归(也就是y值是连续的)，如何应用到分类上去呢。y值确实是一个连续的变量。逻辑回归的做法是划定一个阈值，y值大于这个阈值的是一类，y值小于这个阈值的是另外一类。阈值具体如何调整根据实际情况选择。一般会选择0.5做为阈值来划分。
- 多分类 两种方法处理多分类问题。a：如果K个类别互斥，即当y=i时意味着y不能取其他的值，比如用户的年龄段，则修改损失函数，使用Softmax函数构造模型。Softmax分类模型会输出所有类别的概率，选择输出概率最高的模型。b：如果K个类别不互斥，比如用户会购买哪种品类，则对于每一个类别训练一个二元分类器（one vs all）。

#### 1.7.1、逻辑回归为什么使用sigmoid函数？
A:指数分布族+二项分布推导
B:广义线性模型


### 1.7.2、逻辑回归的损失函数为什么要使用极大似然函数作为损失函数？

 - 损失函数一般有四种，平方损失函数，对数损失函数，HingeLoss0-1损失函数，绝对值损失函数。将极大似然函数取对数以后等同于对数损失函数。在逻辑回归这个模型下，对数损失函数的训练求解参数的速度是比较快的。至于原因大家可以求出这个式子的梯度更新

$$
\theta _j=\theta _j-\left ( y^{i} -h_\theta (x^{i};\theta ) \right )\ast x^{i}_j
$$

这个式子的更新速度只和$x^{i}_j$，$y^{i}$ 相关。和sigmod函数本身的梯度是无关的。这样更新的速度是可以自始至终都比较的稳定。
 - 因为我们想要让每一个样本的预测都要得到最大的概率，即将所有的样本预测后的概率进行相乘都最大，也就是极大似然函数。
 - 为什么不选平方损失函数的呢？其一是因为如果你使用平方损失函数，你会发现梯度更新的速度和sigmod函数本身的梯度是很相关的。sigmod函数在它在定义域内的梯度都不大于0.25。这样训练会非常的慢。


#### 1.8、 逻辑回归在训练的过程当中，如果有很多的特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？
先说结论，如果在损失函数最终收敛的情况下，其实就算有很多特征高度相关也不会影响分类器的效果。
但是对特征本身来说的话，假设只有一个特征，在不考虑采样的情况下，你现在将它重复100遍。训练以后完以后，数据还是这么多，但是这个特征本身重复了100遍，实质上将原来的特征分成了100份，每一个特征都是原来特征权重值的百分之一。
如果在随机采样的情况下，其实训练收敛完以后，还是可以认为这100个特征和原来那一个特征扮演的效果一样，只是可能中间很多特征的值正负相消了。

### 1.9、为什么我们还是会在训练的过程当中将高度相关的特征去掉？
去掉高度相关的特征会让模型的可解释性更好
可以大大提高训练的速度。如果模型当中有很多特征高度相关的话，就算损失函数本身收敛了，但实际上参数是没有收敛的，这样会拉低训练的速度。其次是特征多了，本身就会增大训练的时间。
### 1.10、逻辑回归的优缺点总结
在这里我们总结了逻辑回归应用到工业界当中一些优点：

- 形式简单，模型的可解释性非常好。从特征的权重可以看到不同的特征对最后结果的影响，某个特征的权重值比较高，那么这个特征最后对结果的影响会比较大。
- 模型效果不错。在工程上是可以接受的（作为baseline)，如果特征工程做的好，效果不会太差，并且特征工程可以大家并行开发，大大加快开发的速度。
- 训练速度较快。分类的时候，计算量仅仅只和特征的数目相关。并且逻辑回归的分布式优化sgd发展比较成熟，训练的速度可以通过堆机器进一步提高，这样我们可以在短时间内迭代好几个版本的模型。
- 资源占用小,尤其是内存。因为只需要存储各个维度的特征值，。
- 方便输出结果调整。逻辑回归可以很方便的得到最后的分类结果，因为输出的是每个样本的概率分数，我们可以很容易的对这些概率分数进行cutoff，也就是划分阈值(大于某个阈值的是一类，小于某个阈值的是一类)。

但是逻辑回归本身也有许多的缺点:

- 准确率并不是很高。因为形式非常的简单(非常类似线性模型)，很难去拟合数据的真实分布。
- 很难处理数据不平衡的问题。举个例子：如果我们对于一个正负样本非常不平衡的问题比如正负样本比 10000:1.我们把所有样本都预测为正也能使损失函数的值比较小。但是作为一个分类器，它对正负样本的区分能力不会很好。
- 处理非线性数据较麻烦。逻辑回归在不引入其他方法的情况下，只能处理线性可分的数据，或者进一步说，处理二分类的问题 。
- 逻辑回归本身无法筛选特征。有时候，我们会用gbdt来筛选特征，然后再上逻辑回归。

### 1.11、为什么LR需要归一化或者取对数,离散化LR的好处,为什么把特征组合之后还能提升
取对数:基于对数函数在其定义域内是单调增函数，取对数后不会改变数据的相对关系
归一化:可以提高收敛速度，提高收敛的精度，归一化也有利于梯度下降；

在工业界，很少直接将连续值作为特征喂给逻辑回归模型，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型，这样做的优势有以下几点：

 - 稀疏向量内积乘法运算速度快，计算结果方便存储，容易scalable（扩展）。

 - 离散化后的特征对异常数据有很强的鲁棒性：比如一个特征是年龄>30是1，否则0。如果特征没有离散化，一个异常数据“年龄300岁”会给模型造成很大的干扰。
 - 逻辑回归属于广义线性模型，表达能力受限；单变量离散化为N个后，每个变量有单独的权重，相当于为模型引入了非线性，能够提升模型表达能力，加大拟合。

 - 离散化后可以进行特征交叉，由M+N个变量变为M*N个变量，进一步引入非线性，提升表达能力。

 - 特征离散化后，模型会更稳定，比如如果对用户年龄离散化，20-30作为一个区间，不会因为一个用户年龄长了一岁就变成一个完全不同的人。当然处于区间相邻处的样本会刚好相反，所以怎么划分区间是门学问。

特征组合，实际上做的就是空间变换，更准确说是把原有的特征空间映射到了一个更加高维的特征空间中。在一个真实问题中，我们并不知道分界线到底是圆还是双曲线还是别的什么，所以对于上面的例子，我们一般会尝试把原来的（x1,x2）映射到（x1,x2,x1^2,x2^2,x1x2），正所谓扩大搜索范围。特征组合增强了特征的表达能力，基本等价于说高维空间比低维空间更有表达力。

### 1.12、 LR推导（伯努利过程，极大似然，损失函数，梯度下降）有没有最优解？

逻辑回归的损失函数是凸函数（加入正则项后是严格凸函数），可以保证我们找到的局部最优值同时是全局最优。此外，常用的凸优化的方法都可以用于求解该问题。例如共轭梯度下降，牛顿法，LBFGS等。

目标函数$f(x)=e^{-\theta^Tx}$，无约束条件。这是凸优化问题。首先目标函数是凸的，其次无约束的话，可行域是整个向量空间，是凸集。但是这个问题没有最优解。无约束的凸优化问题可能无下界（e.g.线性函数）或最优值有限但不可达（本例），存在最优解的充要条件是存在一阶导数为零的点。
逻辑回归是凸优化问题，凸函数+无约束条件。有最优解是因为存在一阶导数为零的点。

### 1.13、LR可以用核么？可以怎么用？ LR可以用来处理非线性问题么？l1和l2正则项是啥？lr加l1还是l2好？加哪个可以用核（加l2正则项，和svm类似，加l2正则项可以用核方便处理） TD
LR可以使用核函数，使用核函数可以解决非线性分类问题。加核是显式地把特征映射到高维 然后再做lr。
不过，通常使用的kernel都是隐式的，也就是找不到显式地把数据从低维映射到高维的函数，而只能计算高维空间中数据点的内积。在这种情况下，logistic regression模型就不能再表示成![wx+b](https://www.zhihu.com/equation?tex=w%5ETx%2Bb)的形式（primal form），而只能表示成![b](https://www.zhihu.com/equation?tex=%5Csum_i+a_i+%5Clangle+x_i%2Cx+%5Crangle+%2Bb)的形式（dual form）。忽略那个b的话，primal form的模型的参数只有w，只需要一个数据点那么多的存储量；而dual form的模型不仅要存储各个ai，还要存储训练数据本身xi，这个存储量就大了。
SVM也是具有上面两种形式的。不过，与logistic regression相比，它的dual form是稀疏的——只有支持向量的ai才非零，才需要存储相应的xi。所以，在非线性可分的情况下，SVM用得更多。

### 1.14 SVM和logistic回归分别在什么情况下使用？
两种方法都是常见的分类算法，从目标函数来看，区别在于逻辑回归采用的是logistical loss，svm采用的是hinge loss。这两个损失函数的目的都是增加对分类影响较大的数据点的权重，减少与分类关系较小的数据点的权重。SVM的处理方法是只考虑support vectors，也就是和分类最相关的少数点，去学习分类器。而逻辑回归通过非线性映射，大大减小了离分类平面较远的点的权重，相对提升了与分类最相关的数据点的权重。两者的根本目的都是一样的。此外，根据需要，两个方法都可以增加不同的正则化项，如l1,l2等等。所以在很多实验中，两种算法的结果是很接近的。但是逻辑回归相对来说模型更简单，好理解，实现起来，特别是大规模线性分类时比较方便。而SVM的理解和优化相对来说复杂一些。但是SVM的理论基础更加牢固，有一套结构化风险最小化的理论基础，虽然一般使用的人不太会去关注。还有很重要的一点，SVM转化为对偶问题后，分类只需要计算与少数几个支持向量的距离，这个在进行复杂核函数计算时优势很明显，能够大大简化模型和计算量。

### 1.15 naive bayes和logistic regression的区别
(1) Naive Bayes是一个生成模型，在计算P(y|x)之前，先要从训练数据中计算P(x|y)和P(y)的概率，从而利用贝叶斯公式计算P(y|x)。Logistic Regression是一个判别模型，它通过在训练数据集上最大化判别函数P(y|x)学习得到，不需要知道P(x|y)和P(y)。
(2) Naive Bayes是建立在条件独立假设基础之上的，设特征X含有n个特征属性（X1，X2，...Xn），那么在给定Y的情况下，X1，X2，...Xn是条件独立的。Logistic Regression的限制则要宽松很多，如果数据满徐条件独立假设，Logistic Regression能够取得非常好的效果；当数据不满度条件独立假设时，Logistic Regression仍然能够通过调整参数让模型最大化的符合数据的分布，从而训练得到在现有数据集下的一个最优模型。
- 相同点
Logistic regression和Naive bayes都是对特征的线性表达。
Logistic regression和Naive bayes建模的都是条件概率  ，对所最终求得的不同类的结果有很好的解释性。而不像SVM，神经网络这样解释性不高。
- 不同点
Logistic regression在有相关性feature上面学习得到的模型在测试数据的performance更好。也就是说，logistic regression在训练时，不管特征之间有没有相关性，它都能找到最优的参数。而在Naive bayes中，由于我们给定特征直接相互独立的严格设定，在有相关性的feature上面学习到的权重同时变大或变小，它们之间的权重不会相互影响。从这方面来说，如果能够在对参数较好地控制，在损失项方面处理的很好的话，Logistic regression相对Naive bayes在应用时更不会限制在特征工程（feature engineering）上面。

## 二 GBDT系列（重点）
机器学习的话，gbdt肯定是重中之重了，跟LR一样是最最最常见的问题，工业界应用也很多，打比赛就不用说，xgb lgb是历届kaggle的两把快刀。

其实gbdt没有太多可说的，无非是boosting思想啊，为啥用负梯度啊之类。重点是在lgb和xgb对传统gbdt的优化上,[总结](http://djjowfy.com/2017/08/01/XGBoost%E7%9A%84%E5%8E%9F%E7%90%86/)。
## 三 SVM
[推导](https://www.zhihu.com/question/21094489)
## 四 RF&bagging 集成学习
随机森林本身没啥东西，不过bagging的思想倒是非常有用，比赛中常用的降低过拟合方案，简单来说就是选xgb中偏差低方差高的模型，做bagging，效果非常显著。再有一点就是RF可以用oob做特征选择，效果也不错。

#### 4.1 集成学习概述
从下图，我们可以对集成学习（ensemble learning）的思想做一个概括。对于训练集数据，我们通过训练若干个个体学习器，通过一定的结合策略，就可以最终形成一个强学习器，以达到博采众长的目的。
![el](https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161204191919974-1029671964.png)
##### 集成学习基本问题
- 集成学习的核心是将多个

##### 集成学习的基本思想
- 结合多个学习器组合成一个性能更好的学习器

##### 集成学习为什么有效？
- 不同的模型通常会在**测试集**上产生不同的误差；如果成员的误差是独立的，集成模型将显著地比其成员表现更好。

#### 4.1 集成学习之个体学习器
   上一节我们讲到，集成学习的第一个问题就是如何得到若干个个体学习器。这里我们有两种选择。
   第一种就是所有的个体学习器都是一个种类的，或者说是同质的。比如都是决策树个体学习器，或者都是神经网络个体学习器。第二种是所有的个体学习器不全是一个种类的，或者说是异质的。比如我们有一个分类问题，对训练集采用支持向量机个体学习器，逻辑回归个体学习器和朴素贝叶斯个体学习器来学习，再通过某种结合策略来确定最终的分类强学习器。
   目前来说，同质个体学习器的应用是最广泛的，一般我们常说的集成学习的方法都是指的同质个体学习器。而同质个体学习器使用最多的模型是CART决策树和神经网络。同质个体学习器按照个体学习器之间是否存在依赖关系可以分为两类，第一个是个体学习器之间存在强依赖关系，一系列个体学习器基本都需要**串行**生成，代表算法是boosting系列算法，第二个是个体学习器之间不存在强依赖关系，一系列个体学习器可以**并行**生成，代表算法是bagging和随机森林（Random Forest）系列算法。下面就分别对这两类算法做一个概括总结。

#### 4.2 集成学习之boosting
boosting的算法原理我们可以用一张图做一个概括如下：
![boosting](https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161204194331365-2142863547.png)

- 基于**串行策略**：基学习器之间存在依赖关系，新的学习器需要根据上一个学习器生成。
- **基本思路**：
  - 先从**初始训练集**训练一个基学习器；初始训练集中各样本的权重是相同的；
  - 根据上一个基学习器的表现，**调整样本权重**，使分类错误的样本得到更多的关注；
  - 基于调整后的样本分布，训练下一个基学习器；
  - 测试时，对各基学习器**加权**得到最终结果
- **特点**：
  - 每次学习都会使用全部训练样本
- **代表算法**：
  - AdaBoost 算法
  - GBDT 算法

#### 4.3 集成学习之bagging
Bagging的算法原理和 boosting不同，它的弱学习器之间没有依赖关系，可以并行生成，我们可以用一张图做一个概括如下：
![bagging](https://images2015.cnblogs.com/blog/1042406/201612/1042406-20161204200000787-1988863729.png)
- 基于**并行策略**：基学习器之间不存在依赖关系，可同时生成。
- **基本思路**：
  - 利用**自助采样法**对训练集随机采样，重复进行 `T` 次;
  - 基于每个采样集训练一个基学习器，并得到 `T` 个基学习器；
  - 预测时，集体**投票决策****。
    > **自助采样法**：对 m 个样本的训练集，有放回的采样 m 次；此时，样本在 m 次采样中始终没被采样的概率约为 `0.368`，即每次自助采样只能采样到全部样本的 `63%` 左右。
    >
$$
\lim_{m\to\infty}\left ( 1-\frac{1}{m} \right )^m\rightarrow \frac{1}{e}\approx 0.368
$$
- **特点**：
  - 训练每个基学习器时只使用一部分样本；
  - 偏好**不稳定**的学习器作为基学习器；
    
   > 所谓不稳定的学习器，指的是对**样本分布**较为敏感的学习器。

#### 4.4 集成学习之stacking
- 基于**串行策略**：初级学习器与次级学习器之间存在依赖关系，初学习器的输出作为次级学习器的输入。
- **基本思路**：
  - 先从初始训练集训练 `T` 个**不同的初级学习器**;
  - 利用每个初级学习器的**输出**构建一个**次级数据集**，该数据集依然使用初始数据集的标签；
  - 根据新的数据集训练**次级学习器**；
  - **多级学习器**的构建过程类似。
> 周志华-《机器学习》中没有将 Stacking 方法当作一种集成策略，而是作为一种**结合策略**，比如**加权平均**和**投票**都属于结合策略。

- 为了降低过拟合的风险，一般会利用**交叉验证**的方法使不同的初级学习器在**不完全相同的子集**上训练
  ```tex
  以 k-折交叉验证为例：
  - 初始训练集 D={(x_i, y_i)} 被划分成 D1, D2, .., Dk；
  - 记 h_t 表示第 t 个学习器，并在除 Dj 外的数据上训练；
  - 当 h_t 训练完毕后，有 z_it = h_t(x_i)；
  - T 个初级学习器在 x_i 上共产生 T 个输出；
  - 这 T 个输出共同构成第 i 个次级训练数据 z_i = (z_i1, z_i2, ..., z_iT)，标签依然为 y_i；
  - 在 T 个初级学习器都训练完毕后，得到次级训练集 D'={(z_i, y_i)}
  ```

#### 为什么使用决策树作为基学习器？

- **类似问题**
  - 基学习器有什么特点？
  - 基学习器有什么要求？

- 使用决策树作为基学习器的原因：
  ```tex
  (1). 决策树的表达能力和泛化能力，可以通过剪枝快速调整；
  (2). 决策树可以方便地将**样本的权重**整合到训练过程中；
  (3). 决策树是一种**不稳定**的学习器；
       所谓不稳定，指的是数据样本的扰动会对决策树的结果产生较大的影响；
  ```
  - 后两点分别适合 Boosting 策略和 Bagging 策略；所以它们一般都使用决策树作为基学习器。
  
#### 为什么不稳定的学习器更适合作为基学习器？
- 不稳定的学习器容易受到**样本分布**的影响（方差大），很好的引入了**随机性**；这有助于在集成学习（特别是采用 **Bagging** 策略）中提升模型的**泛化能力**。
- 为了更好的引入随机性，有时会随机选择一个**属性子集**中的最优分裂属性，而不是全局最优（**随机森林**）

#### 还有哪些模型也适合作为基学习器？
- **神经网络**
  - 神经网络也属于**不稳定**的学习器；
  - 此外，通过调整神经元的数量、网络层数，连接方式初始权重也能很好的引入随机性和改变模型的表达能力和泛化能力。

#### Bagging 方法中能使用线性分类器作为基学习器吗？ Boosting 呢？
- Bagging 方法中**不推荐**
  - 线性分类器都属于稳定的学习器（方差小），对数据不敏感；
  - 甚至可能因为 Bagging 的采样，导致在训练中难以收敛，增大集成分类器的**偏差**
- Boosting 方法中可以使用
  - Boosting 方法主要通过降低**偏差**的方式来提升模型的性能，而线性分类器本身具有方差小的特点，所以两者有一定相性
  - XGBoost 中就支持以线性分类器作为基学习器。

#### Boosting/Bagging 与 偏差/方差 的关系
> ./机器学习基础/[偏差与方差](./ML-A-机器学习基础.md#偏差与方差)

- 简单来说，**Boosting** 能提升弱分类器性能的原因是降低了**偏差**；**Bagging** 则是降低了**方差**；
- **Boosting** 方法：
  - Boosting 的**基本思路**就是在不断减小模型的**训练误差**（拟合残差或者加大错类的权重），加强模型的学习能力，从而减小偏差；
  - 但 Boosting 不会显著降低方差，因为其训练过程中各基学习器是强相关的，缺少独立性。
- **Bagging** 方法：
  - 对 `n` 个**独立不相关的模型**预测结果取平均，方差是原来的 `1/n`；
  - 假设所有基分类器出错的概率是独立的，**超过半数**基分类器出错的概率会随着基分类器的数量增加而下降。
- 泛化误差、偏差、方差、过拟合、欠拟合、模型复杂度（模型容量）的关系图：

## 五 决策树
怎么说呢，问的也比较少了，就是三种树，ID3，C4.5，CART，区别和剪枝记一记。
#### 1、简单介绍决策树
ID3，C4.5，CART，分别用信息增益，信息增益比和gini系数作为分裂节点的依据

#### 2、ID3 怎么做特征的离散化的

#### 3、预剪枝和后剪枝

 预剪枝


 - 预剪枝就是在完全正确分类训练集之前，较早地停止树的生长。 具体在什么时候停止决策树的生长有多种不同的方法:
(1) 一种最为简单的方法就是在决策树到达一定高度的情况下就停止树的生长。
(2) 到达此结点的实例具有相同的特征向量，而不必一定属于同一类， 也可停止生长。
(3) 到达此结点的实例个数小于某一个阈值也可停止树的生长。
(4) 还有一种更为普遍的做法是计算每次扩张对系统性能的增益，如果这个增益值小于某个阈值则不进行扩展。
 - 优点&缺点
   - 由于预剪枝不必生成整棵决策树，且算法相对简单，效率很高， 适合解决大规模问题。但是尽管这一方法看起来很直接，但是 怎样精确地估计何时停止树的增长是相当困难的。
   - 预剪枝有一个缺点， 即视野效果问题 。 也就是说在相同的标准下，也许当前的扩展会造成过度拟合训练数据，但是更进一步的扩展能够满足要求，也有可能准确地拟合训练数据。这将使得算法过早地停止决策树的构造。

后剪枝
后剪枝，在已生成过拟合决策树上进行剪枝，可以得到简化版的剪枝决策树。

主要有四种：

 - REP-错误率降低剪枝
 - PEP-悲观剪枝
 - CCP-代价复杂度剪枝
 - MEP-最小错误剪枝

## 六 特征选择方法（重点）
特征选择是模型预处理的重要部分。方法很多：方差、相关系数、卡方检验、互信息、递归特征消除、基于惩罚的方法、树模型方法、单特征AUC、IV。

## 七 采样方法
主要有过采样和欠采样。

过采样：Smote方法及各种变种

欠采样：ensemble、nearMiss、Tomeklink、ENN

还有复杂分布的采样会用到MCMC。

## 八 聚类方法
k-means、k-means++、meanshift、DBSCAN、EM聚类、层次聚类。

## 九 评估指标（重点）
精准率、召回率、ACC、AUC、F1、KS、熵系列、信息增益、CTR、CVR、MSE系列。其中AUC是重点中的重点，被问了好多次，而且很细节，包括本质意义、计算方法等等，注意AUC是有两种计算方法的，[这里](https://www.cnblogs.com/peizhe123/p/5081559.html)有介绍。

## 十 欠拟合与过拟合（重点）
起因基本不太会考，解决方法就多了，降低模型复杂程度啊，dropout啊、bagging、正则、earlystop，数据增强、交叉验证。Dropout本质也是个bagging。
#### 10.1 如何解决欠拟合：
1. 添加其他特征项。组合、泛化、相关性、上下文特征、平台特征等特征是特征添加
的重要手段，有时候特征项不够会导致模型欠拟合。
2. 添加多项式特征。例如将线性模型添加二次项或三次项使模型泛化能力更强。例
如，FM（Factorization Machine）模型、FFM（Field-aware Factorization
Machine）模型，其实就是线性模型，增加了二阶多项式，保证了模型一定的拟合程
度。
3. 可以增加模型的复杂程度。
4. 减小正则化系数。正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟
合，则需要减少正则化参数。
#### 10.2 如何解决过拟合：
1. 重新清洗数据，数据不纯会导致过拟合，此类情况需要重新清洗数据。
2. 增加训练样本数量。
3. 降低模型复杂程度。
4. 正则化。
正则化的思想十分简单明了。由于模型过拟合极有可能是因为我们的模型过于复杂。因此，我们需要让我们的模型在训练的时候，在对损失函数进行最小化的同时，也需要让对参数添加限制，这个限制也就是正则化惩罚项。
5. 采用dropout方法，dropout方法，通俗的讲就是在训练的时候让神经元以一定的概率不工作。
在神经网络产生过拟合主要是因为神经元之间的协同作用产生的。因此在神经网络进行训练的时候，让部分神经元失活，这样就阻断了部分神经元之间的协同作用，从而强制要求一个神经元和随机挑选出的神经元共同进行工作，减轻了部分神经元之间的联合适应性。![EIOMvV.md.png](https://s2.ax1x.com/2019/05/14/EIOMvV.png)


6. early stopping。
在对模型进行训练时，我们可以将我们的数据集分为三个部分，训练集、验证集、测试集。我们在训练的过程中，可以每隔一定量的step，使用验证集对训练的模型进行预测，一般来说，模型在训练集和验证集的损失变化如下图所示： 
7. 减少迭代次数。
8. 增大学习率。 
9. 添加噪声数据。
10. 树结构中，可以对树进行剪枝。
11. 减少特征项。



## 十一 batch normalization
[总结](https://www.zhihu.com/question/38102762/answer/302841181)

## 十二 梯度弥散/爆炸，怎么解决
改激活函数啊，BN啊，想lstm一样把*变+啊，加恒等映射的跳跃层啊，都可以。没有太好的文章，看看[这篇](https://zhuanlan.zhihu.com/p/28124810)讲resnet的吧。



## 十三 激活函数，比较

sigmod tanh relu maxout... 好多，这个随便一搜就一堆，放一个不太切题的文章吧，[回答。](https://www.zhihu.com/question/61265076/answer/186347780)

## 十四 优化方法（重点）

这就很多了，梯度下降系列、牛顿法系列，还有传统的模拟退火、遗传算法。牛顿法这回问的很多，不知道为啥。lan大神的花书讲的就很好，梯度下降的可以看[这个](https://blog.csdn.net/tsyccnh/article/details/76270707) 。这里要注意，有些面试官会让你实操，就比如给你一个方程，让你用梯度下降求解。

#### 1、谈谈牛顿法
收敛速度快，指数级收敛，但是不保证线性收敛，只保证二阶导收敛
#### 2、牛顿法怎么优化
记得看到过，忘了，没答上来
Cross Encropy是怎么推导出来的
没答上来，只说了熵怎么求，GG

## 十五 各种网络结构&模型（重点）

这个就太多了，CNN RNN就一堆，推荐的也是一堆，基本的DNN CNN RNN的forward和backprob都要熟悉，然后lstm、gru、attention也要会，还有各种encoder-decoder结构，这个就看积累了。 推荐部分有自己的一些模型，比如FM系列，lookalike、协同过滤之类的非深度学习模型，后面的W&D为首的融合模型也是搭积木。

